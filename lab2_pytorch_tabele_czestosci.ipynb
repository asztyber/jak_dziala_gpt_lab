{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6896dc-1fa8-4f59-98b3-888687bc5d3d",
   "metadata": {},
   "source": [
    "Imię i nazwisko: ....\n",
    "\n",
    "Punktacja:\n",
    " * poprawnie działający kod 6 pkt.\n",
    " * wnioski 2 pkt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae8f188-b978-4b06-9139-bcbd7556889d",
   "metadata": {
    "id": "fae8f188-b978-4b06-9139-bcbd7556889d"
   },
   "source": [
    "## LAB 2 Jak działa GPT\n",
    "### Wprowadzenie do biblioteki PyTorch i przetwarzania danych tekstowych - predykcja następnego znaku w tekście\n",
    "\n",
    "Celem laboratorium jest:\n",
    "* wprowadzenie do przetwarzania danych tekstowych\n",
    "* ćwiczenie umiejętności wykorzystania biblioteki PyTorch\n",
    "\n",
    "W ramach laboratorium należy napisać program przewidujący kolejny znak w tekście z wykorzystaniem tabeli częstości.\n",
    "\n",
    "Laboratorium obejmuje:\n",
    "1. Generację tekstu na podstawie macierzy zliczeń częstości (fragmenty kodu do uzupełnienia)\n",
    "2. Przygotowanie danych do uczenia macierzy częstości (proszę się zapoznać)\n",
    "3. Wyznaczanie macierzy częstości z wykorzystaniem algorytmów optymalizacji gradientowej (fragmenty kodu do uzupełnienia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b815a2-a599-488c-9eb7-b27505f5df55",
   "metadata": {
    "id": "21b815a2-a599-488c-9eb7-b27505f5df55"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db56d19-c236-4e37-a98b-ca7f3253a75a",
   "metadata": {
    "id": "8db56d19-c236-4e37-a98b-ca7f3253a75a"
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ipdVXUVdoaga",
   "metadata": {
    "id": "ipdVXUVdoaga"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://github.com/asztyber/jak_dziala_gpt_lab/blob/main/data/hpmor_part.txt?raw=true\"\n",
    "response = requests.get(url)\n",
    "text = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47c7a7-c56f-45de-827a-87444b116cc2",
   "metadata": {
    "id": "2b47c7a7-c56f-45de-827a-87444b116cc2"
   },
   "source": [
    "### Dane\n",
    "Będziemy pracować na fragmencie książki: Eliezer Yudkowsky, [Harry Potter and the Methods of Rationality](https://hpmor.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a006bd0-edd7-491e-af7f-901e87d97dd2",
   "metadata": {
    "id": "2a006bd0-edd7-491e-af7f-901e87d97dd2"
   },
   "outputs": [],
   "source": [
    "# fragment tekstu\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13774288-adbc-46c6-b32f-b100293a88a8",
   "metadata": {
    "id": "13774288-adbc-46c6-b32f-b100293a88a8"
   },
   "outputs": [],
   "source": [
    "# długość tekstu - w znakach\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027e727-a78e-464d-bda7-f6ee60f0923d",
   "metadata": {
    "id": "6027e727-a78e-464d-bda7-f6ee60f0923d"
   },
   "source": [
    "### Predykcja kolejnego znaku na podstawie poprzedniego na podstawie zliczeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2eb284-8141-48d4-9727-1481b1004be3",
   "metadata": {
    "id": "5b2eb284-8141-48d4-9727-1481b1004be3"
   },
   "outputs": [],
   "source": [
    "# chars - zawiera wszystkie znaki w tekście\n",
    "chars = sorted(list(set(text)))\n",
    "n_tokens = len(chars) # liczba znaków\n",
    "print(len(chars))\n",
    "print(chars)\n",
    "# uwaga mamy tu tylko znaki występujące w tekście wybranym do uczenia (np. brak 'K' i 'Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da43e9-21a5-4967-b8f1-6523764ac4c3",
   "metadata": {
    "id": "16da43e9-21a5-4967-b8f1-6523764ac4c3"
   },
   "outputs": [],
   "source": [
    "# w dalszym ciągu będziemy się posługiwać indeksami znaków zamiast znakami (jest to odpowiednik tokenów)\n",
    "# przygotowujemy dwa słowniki\n",
    "# idx_to_ch - indeks -> znak\n",
    "# ch_to_idx - znak -> indeks\n",
    "idx_to_ch = {i: c for i, c in enumerate(chars)}\n",
    "ch_to_idx = {c: i for i, c in enumerate(chars)}\n",
    "print(idx_to_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a42b48-bca2-4951-af14-4778363ada83",
   "metadata": {
    "id": "22a42b48-bca2-4951-af14-4778363ada83"
   },
   "outputs": [],
   "source": [
    "print(ch_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37864922-ead7-4569-b8b1-7a6d621ec0b1",
   "metadata": {
    "id": "37864922-ead7-4569-b8b1-7a6d621ec0b1"
   },
   "source": [
    "#### Macierz zliczeń znaków\n",
    "Chcemy wyznaczyć macierz zawierającą informację, jak często po jakimś znaku występował innych znak.\n",
    "Przykładowo na pozycji (indeks znaku 'a', indeks znaku 'b') chcemy mieć informację, ile razy w tekście po znaku 'a' wystąpił znak 'b'\n",
    "\n",
    "<img src=\"https://github.com/asztyber/jak_dziala_gpt_lab/blob/main/pic/counts_arr.png?raw=1\" alt=\"Macierz zliczeń\" width=\"500\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495b602-3745-4ec6-98e3-f64858713f95",
   "metadata": {
    "id": "4495b602-3745-4ec6-98e3-f64858713f95"
   },
   "source": [
    "Zaczynamy z pustej macierzy. Proszę utworzyć tensor o wymiarze liczba znaków x liczba znaków ($n\\_tokens$) wypełniony zerami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc063b52-5e71-4c75-830d-1af084697195",
   "metadata": {
    "id": "fc063b52-5e71-4c75-830d-1af084697195"
   },
   "outputs": [],
   "source": [
    "counts_arr = # TODO\n",
    "print(counts_arr.dtype)\n",
    "counts_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc56123-f244-442e-be75-204032ca739a",
   "metadata": {
    "id": "bfc56123-f244-442e-be75-204032ca739a"
   },
   "source": [
    "##### Przykład jak zgrabnie pętlą for wybrać pary (znak, następny znak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b38c8-461f-4177-a113-ed5b28293948",
   "metadata": {
    "id": "ba3b38c8-461f-4177-a113-ed5b28293948"
   },
   "outputs": [],
   "source": [
    "short_text = text[:15] # wybieramy do demonstracji pierwsze 15 znaków\n",
    "print(\"Pierwsze 15 znaków: \", short_text)\n",
    "print()\n",
    "print(\"Pary kolejnych znaków:\")\n",
    "for ch1, ch2 in zip(short_text, short_text[1:]):\n",
    "    print(ch1, ch2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b9efa-e064-403e-94e2-baef239f2cea",
   "metadata": {
    "id": "da4b9efa-e064-403e-94e2-baef239f2cea"
   },
   "source": [
    "#### Wypełnić macierz zliczeń zliczeniami wystąpień par znaków\n",
    "* zaktualizuj wartości w macierzy zliczeń\n",
    "* wskazówka: użyj słownika ch_to_idx w celu wyznaczenia indeksów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13c9fa6-25ff-4fd9-ba2a-a0f6003d0328",
   "metadata": {
    "id": "d13c9fa6-25ff-4fd9-ba2a-a0f6003d0328"
   },
   "outputs": [],
   "source": [
    "for ch1, ch2 in zip(text, text[1:]):\n",
    "     #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa79359-03e2-4145-95ff-08e193ceef41",
   "metadata": {
    "id": "aaa79359-03e2-4145-95ff-08e193ceef41"
   },
   "outputs": [],
   "source": [
    "print(\"Długość przetwarzanego tekstu: \", len(text))\n",
    "print(\"Suma zliczeń: \", counts_arr.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea933d-ff61-4c06-80cd-0e1847af5059",
   "metadata": {
    "id": "10ea933d-ff61-4c06-80cd-0e1847af5059"
   },
   "outputs": [],
   "source": [
    "counts_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b42a40f-be6f-4914-9130-56f27e7fb430",
   "metadata": {
    "id": "5b42a40f-be6f-4914-9130-56f27e7fb430"
   },
   "outputs": [],
   "source": [
    "assert torch.allclose(counts_arr.sum(), torch.tensor(len(text) - 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1effa39-2eaa-483d-82df-d15105852eee",
   "metadata": {
    "id": "b1effa39-2eaa-483d-82df-d15105852eee"
   },
   "outputs": [],
   "source": [
    "assert torch.allclose(counts_arr[0, :5], torch.tensor([ 3.,  0., 63.,  1.,  3.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229d9c6-7d1f-47cc-b606-8bf5f92d4ddc",
   "metadata": {
    "id": "d229d9c6-7d1f-47cc-b606-8bf5f92d4ddc"
   },
   "source": [
    "##### Wizualizacja macierzy zliczeń\n",
    "* np. po t często występuje h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3b077-f638-4a73-8718-9e3758f7e915",
   "metadata": {
    "id": "67c3b077-f638-4a73-8718-9e3758f7e915"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(counts_arr, index=ch_to_idx.keys(), columns=ch_to_idx.keys())\n",
    "plt.rc('font', size=6)\n",
    "plt.figure(figsize=(10, 8));\n",
    "sns.heatmap(df, annot=False, cmap=\"coolwarm\", linewidths=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77bee3d-7015-4964-8118-538cdbbb273b",
   "metadata": {
    "id": "e77bee3d-7015-4964-8118-538cdbbb273b"
   },
   "source": [
    "#### Normalizacja wierszy\n",
    "Każdy wiersz macierzy chcemy znormalizować tak, aby wartości w wierszu sumowały się do 1.\n",
    "W ten sposób możemy interpretować dany wiersz jako prawdopodobieństwa wystąpienia kolejnego znaku.\n",
    "\n",
    "<img src=\"https://github.com/asztyber/jak_dziala_gpt_lab/blob/main/pic/counts_arr_norm.png?raw=1\" alt=\"Znormalizowana macierz zliczeń\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e16f5-be1b-4685-8eae-671fe7760b52",
   "metadata": {
    "id": "e02e16f5-be1b-4685-8eae-671fe7760b52"
   },
   "source": [
    "##### Normalizacja macierzy zliczeń\n",
    "Proszę znormalizować macierz zliczeń, tak aby każdy wiersz sumował się do 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16247485-27db-491b-b6f6-397e479f63e7",
   "metadata": {
    "id": "16247485-27db-491b-b6f6-397e479f63e7"
   },
   "outputs": [],
   "source": [
    "norm_counts = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a67bd0-4938-4b46-8819-c59cddf2bd8b",
   "metadata": {
    "id": "01a67bd0-4938-4b46-8819-c59cddf2bd8b"
   },
   "outputs": [],
   "source": [
    "norm_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce725d-8e63-4f7e-a05a-36a7f3635c71",
   "metadata": {
    "id": "68ce725d-8e63-4f7e-a05a-36a7f3635c71"
   },
   "outputs": [],
   "source": [
    "norm_counts.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f19eb-1129-4223-8e6f-a944bd47e9e0",
   "metadata": {
    "id": "d47f19eb-1129-4223-8e6f-a944bd47e9e0"
   },
   "outputs": [],
   "source": [
    "assert torch.allclose(norm_counts.sum(), torch.tensor(float(n_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a89c966-a2f5-4fe7-b0f9-7b86f295e718",
   "metadata": {
    "id": "7a89c966-a2f5-4fe7-b0f9-7b86f295e718"
   },
   "outputs": [],
   "source": [
    "assert torch.allclose(norm_counts[0, :5], torch.tensor([0.001035, 0.000000, 0.021732, 0.000345, 0.001035]), atol = 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1983ea74-cfaf-4170-9e74-8f330dbc7200",
   "metadata": {
    "id": "1983ea74-cfaf-4170-9e74-8f330dbc7200"
   },
   "source": [
    "#### Generacja tekstu\n",
    "* Wyznaczone prawdopodobieństwa wykorzystamy do generacji tekstu - będziemy losować znak po znaku, korzystając z prawdopodobieństw dla następnego znaku.\n",
    "* W każdym momencie patrzymy tylko na jeden ostatni znak, więc wygenerowany tekst zachowuje tylko prawdopodobieństwa par znaków (bigramów), ale nic więcej!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e641b7-7dd1-44e2-9d6b-b57d0edc4226",
   "metadata": {
    "id": "60e641b7-7dd1-44e2-9d6b-b57d0edc4226"
   },
   "outputs": [],
   "source": [
    "# przykładowo obejrzyjmy prawdopodobieństwa kolejnych znaków po 't'\n",
    "next_t = norm_counts[ch_to_idx['t']]\n",
    "next_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629cfce6-d461-4f27-845b-126fe8c0d2ba",
   "metadata": {
    "id": "629cfce6-d461-4f27-845b-126fe8c0d2ba"
   },
   "outputs": [],
   "source": [
    "# wydruk par - znak prawdopodobieństwo\n",
    "for c, p in zip(chars, list(next_t)):\n",
    "    print(c, f'{p.item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e48eed-81a3-4b33-89a9-55de614a998f",
   "metadata": {
    "id": "f7e48eed-81a3-4b33-89a9-55de614a998f"
   },
   "outputs": [],
   "source": [
    "# przykład losowania znaku występującego po 't' (można uruchomić kilka razy i zobaczyć co się losuje)\n",
    "idx_to_ch[np.random.choice(n_tokens, p=next_t)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e975d-fcce-4aa3-8f9d-59f9412968f8",
   "metadata": {
    "id": "055e975d-fcce-4aa3-8f9d-59f9412968f8"
   },
   "source": [
    "#### Regularyzacja\n",
    "Problem - jeśli w macierzy mamy na danej pozycji 0 - to nigdy nie wylosujemy danej pary.\n",
    "Dodajemy do każdej pozycji macierzy małą liczbę 0.001, żeby każda z par czasem mogła się pojawić.\n",
    "* Proszę dodać 0.001 do wszystkich pozycji macierzy zliczeń **podstawowej, nie znormalizowanej**\n",
    "* A następnie ponownie znormalizować"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428ffce-13ea-4521-895a-da0089561c44",
   "metadata": {
    "id": "8428ffce-13ea-4521-895a-da0089561c44"
   },
   "outputs": [],
   "source": [
    "counts_arr_reg = # TODO\n",
    "norm_counts =  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3813451-fc73-4f08-be93-d8db7f2e4a6a",
   "metadata": {
    "id": "e3813451-fc73-4f08-be93-d8db7f2e4a6a"
   },
   "outputs": [],
   "source": [
    "assert torch.allclose(norm_counts.sum(), torch.tensor(float(n_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dfd9ac-fdff-48c3-8a71-62577a7aebfb",
   "metadata": {
    "id": "43dfd9ac-fdff-48c3-8a71-62577a7aebfb"
   },
   "outputs": [],
   "source": [
    "assert torch.allclose(norm_counts[0, :5], torch.tensor([0.0010352, 0.0000003, 0.0217315, 0.0003453, 0.0010352]), atol = 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f7bc83-ac64-4d50-b9ae-f5295b5442c6",
   "metadata": {
    "id": "f7f7bc83-ac64-4d50-b9ae-f5295b5442c6"
   },
   "source": [
    "#### Napisz funkcję generującą tekst na podstawie wyznaczonej macierzy zliczeń\n",
    "Dopóki nie wykonamy założonej liczby iteracji:\n",
    "* wybierz ostatni znak tekstu\n",
    "* odczytaj ze znormalizowanej macierzy zliczeń prawdopodobieństwa następnego znaku\n",
    "* zmień tensor prawdopodobieństw na macierz numpy (probs = probs.detach().numpy(), detach() powoduje, że dalsze obliczenia nie są wykorzystywane do wyliczania gradientów)\n",
    "* wylosuj kolejny znak (wskazówka: np.random.choice)\n",
    "* dodaj wylosowany znak do generowanego tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e6605-b2e5-40f2-8e6f-9dc74f4bb8ed",
   "metadata": {
    "id": "cb6e6605-b2e5-40f2-8e6f-9dc74f4bb8ed"
   },
   "outputs": [],
   "source": [
    "def generate_text(start_seq, norm_counts, max_size):\n",
    "    '''\n",
    "    Funkcja generuje tekst.\n",
    "    start_seq (str) - początek tekstu, podany przez użytkownika\n",
    "    norm_counts - znormalizowana macierz zliczeń\n",
    "    max_size (int) - zadana liczba iteracji - ile znaków tekstu generujemy\n",
    "    '''\n",
    "    for i in range(max_size):\n",
    "        # TODO\n",
    "        # TODO\n",
    "        # TODO\n",
    "        # TODO\n",
    "        start_seq += next_ch\n",
    "    return start_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da3225a-ee04-442c-95d2-0ce683bc56d4",
   "metadata": {
    "id": "3da3225a-ee04-442c-95d2-0ce683bc56d4"
   },
   "outputs": [],
   "source": [
    "print(generate_text(\"T\", norm_counts, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6af07f-8b0d-4a24-943f-736c2f10e4cb",
   "metadata": {
    "id": "0e6af07f-8b0d-4a24-943f-736c2f10e4cb"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "assert generate_text(\"The\", norm_counts, 20) == 'Thede be amelepes pel. '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b9c6aa-598f-48b3-b7ac-0d0611174694",
   "metadata": {
    "id": "f0b9c6aa-598f-48b3-b7ac-0d0611174694"
   },
   "source": [
    "#### Porównanie z losową macierzą zliczeń\n",
    "* Cóż wygnerowany tekst pozostawia nieco do życzenia\n",
    "* Ale porównamy go z macierzą zliczeń wygenerowaną losowo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de7c17-93ea-4341-a289-f97d1362874c",
   "metadata": {
    "id": "f1de7c17-93ea-4341-a289-f97d1362874c"
   },
   "outputs": [],
   "source": [
    "# losowa macierz zliczeń\n",
    "rand_counts = torch.randint(high=100, size=(n_tokens, n_tokens))\n",
    "rand_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cec429-371d-4e27-9fee-75a9bb07aaeb",
   "metadata": {
    "id": "26cec429-371d-4e27-9fee-75a9bb07aaeb"
   },
   "outputs": [],
   "source": [
    "rand_counts_reg = rand_counts + 0.001\n",
    "norm_rand_counts = rand_counts_reg/rand_counts_reg.sum(axis=1, keepdims=True)\n",
    "norm_rand_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8350a6-f61e-42a6-8a86-de0f0ad990c7",
   "metadata": {
    "id": "1b8350a6-f61e-42a6-8a86-de0f0ad990c7"
   },
   "outputs": [],
   "source": [
    "print(generate_text(\"T\", norm_rand_counts, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02aa53-25fa-44e8-80c3-3c35b0d6ff22",
   "metadata": {
    "id": "2c02aa53-25fa-44e8-80c3-3c35b0d6ff22"
   },
   "source": [
    "### Uczenie się macierzy zliczeń z wykorzystaniem algorytmów gradientowych\n",
    "* A teraz wyznaczymy macierz zliczeń stosując optymalizację gradientową\n",
    "* Samo w sobie nie jest to specjalnie sensowne - celem zadania jest oswojenie się z PyTorchem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7943429-dda1-45df-bfbe-ecbcca890095",
   "metadata": {
    "id": "f7943429-dda1-45df-bfbe-ecbcca890095"
   },
   "source": [
    "##### Incijalizacja macierzy wag\n",
    "* zainicjalizuj macierz wag liczbami losowymi z rozkładu normalnego o średniej 0 i odchyleniu standardowym 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8cfd65-0a0f-4e4e-be3f-f14e20664544",
   "metadata": {
    "id": "3d8cfd65-0a0f-4e4e-be3f-f14e20664544"
   },
   "outputs": [],
   "source": [
    "# Zaczynamy z losowej macierzy zliczeń\n",
    "W = # TODO\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1164a09a-4205-48de-bac7-fb6a6833910e",
   "metadata": {
    "id": "1164a09a-4205-48de-bac7-fb6a6833910e"
   },
   "source": [
    "#### Format danych do uczenia\n",
    "* to będzie identyczne również dla bardziej skomplikowanych modeli\n",
    "* reprezentujemy $x$ (znak poprzedni) i $y$ (znak kolejny) jako wektory one hot\n",
    "* mnożenie $x$ przez $W$ wybiera wiersz macierzy dla odpowiedniego indeksu\n",
    "* po zastosowaniu funkcji softmax wybrany wiersz (wektor prawdopodobieństw) porównujemy z $y$ wyliczając entropię krzyżową jako funkcję kosztu\n",
    "* w ten sposób macierz $W$ minimalizująca funkcję kosztu będzie odpowiadała macierzy zliczeń\n",
    "\n",
    "<img src=\"https://github.com/asztyber/jak_dziala_gpt_lab/blob/main/pic/xW_one_hot.png?raw=1\" alt=\"Mnożenie z przez W\" width=\"500\" height=\"300\">\n",
    "\n",
    "##### Dane uczące będziemy przetwarzać w batchach (po kilka przykładów na raz)\n",
    "\n",
    "<img src=\"https://github.com/asztyber/jak_dziala_gpt_lab/blob/main/pic/batch.png?raw=1\" alt=\"Mnożenie z przez W\" width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc598e8-f252-40d3-8486-80af45dd52a7",
   "metadata": {
    "id": "efc598e8-f252-40d3-8486-80af45dd52a7"
   },
   "outputs": [],
   "source": [
    "# wybór kilku indeksów\n",
    "batch_size = 2 # rozmiar batcha\n",
    "rand_idx = np.random.randint(0, len(text) - 1, size=batch_size) # wybieramy batch_size losowych pozycji z tekstu\n",
    "print(rand_idx)\n",
    "x = [text[i] for i in rand_idx] # wybieramy znaki na tych pozycjach\n",
    "y = [text[i + 1] for i in rand_idx] # wybieramy kolejne znaki\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce68198-5b2d-4b16-8dd2-5892ba09a5fd",
   "metadata": {
    "id": "cce68198-5b2d-4b16-8dd2-5892ba09a5fd"
   },
   "outputs": [],
   "source": [
    "# zamianiamy znaki na indeksy (tokeny)\n",
    "x = [ch_to_idx[x[i]] for i in range(batch_size)]\n",
    "y = [ch_to_idx[y[i]] for i in range(batch_size)]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1550cfe0-1ff9-4336-816f-f27ae0cf7198",
   "metadata": {
    "id": "1550cfe0-1ff9-4336-816f-f27ae0cf7198"
   },
   "outputs": [],
   "source": [
    "# zamieniamy na wektory one hot\n",
    "x = [F.one_hot(torch.tensor(x[i]), num_classes=n_tokens) for i in range(batch_size)]\n",
    "y = [F.one_hot(torch.tensor(y[i]), num_classes=n_tokens) for i in range(batch_size)]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595210fb-bc62-42e2-8b11-0a61da512db8",
   "metadata": {
    "id": "595210fb-bc62-42e2-8b11-0a61da512db8"
   },
   "outputs": [],
   "source": [
    "# funkcja stack zamienia listę tensorów na jeden tensor\n",
    "x = torch.stack(x)\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c049d-b01a-4fef-8122-db4516aaebec",
   "metadata": {
    "id": "fa8c049d-b01a-4fef-8122-db4516aaebec"
   },
   "outputs": [],
   "source": [
    "def idx_to_one_hot(idx):\n",
    "    '''\n",
    "    funkcja zamienia listę pozycji w tekście (o długości równej rozmiar batcha) na tensor o wymiarach\n",
    "    (rozmiar batcha x rozmiar słownika) zawierający wektory one hot\n",
    "    '''\n",
    "    x = [text[i] for i in idx]\n",
    "    x = [ch_to_idx[xx] for xx in x]\n",
    "    x = [F.one_hot(torch.tensor(xx, requires_grad=False), num_classes=n_tokens) for xx in x]\n",
    "    x = torch.stack(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1499474-713d-416d-940e-19242c397bb1",
   "metadata": {
    "id": "f1499474-713d-416d-940e-19242c397bb1"
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size=8):\n",
    "    '''\n",
    "    funkcja zwraca batch danych uczących\n",
    "    x i y to tensory o wymiarach (rozmiar batcha x rozmiar słownika) zawierające wektory one hot\n",
    "    '''\n",
    "    rand_idx = np.random.randint(0, len(text) - 1, size=batch_size)\n",
    "    x = idx_to_one_hot(rand_idx).type(torch.float)\n",
    "    y = idx_to_one_hot(rand_idx + 1).type(torch.float)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede61c0-30bf-408c-ae68-505cb522b65f",
   "metadata": {
    "id": "6ede61c0-30bf-408c-ae68-505cb522b65f"
   },
   "outputs": [],
   "source": [
    "x, y = get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3ee20-6b59-4329-affc-ccc1eb616fd8",
   "metadata": {
    "id": "48e3ee20-6b59-4329-affc-ccc1eb616fd8"
   },
   "outputs": [],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e771690-af78-41f9-a608-08e332c26df5",
   "metadata": {
    "id": "0e771690-af78-41f9-a608-08e332c26df5"
   },
   "outputs": [],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36b979-3a83-4c78-b0b7-a218ad91d9dd",
   "metadata": {
    "id": "dd36b979-3a83-4c78-b0b7-a218ad91d9dd"
   },
   "source": [
    "#### Softmax\n",
    "Zaimplementować funkcję softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62c408-4812-4c92-924d-ec9983d57dd8",
   "metadata": {
    "id": "1f62c408-4812-4c92-924d-ec9983d57dd8"
   },
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    # TODO\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae41b7d-ac9b-406d-9289-fd3a4e22006d",
   "metadata": {
    "id": "9ae41b7d-ac9b-406d-9289-fd3a4e22006d"
   },
   "source": [
    "#### Loss\n",
    "Zaimpelemntować entropię krzyżową"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a5659-afdc-4d02-bb04-7282cbc5c4c8",
   "metadata": {
    "id": "5f7a5659-afdc-4d02-bb04-7282cbc5c4c8"
   },
   "outputs": [],
   "source": [
    "def cross_entropy(probs, y_one_hot):\n",
    "    # TODO\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc223b0-a7e7-4558-a80a-32e982231bfb",
   "metadata": {
    "id": "8bc223b0-a7e7-4558-a80a-32e982231bfb"
   },
   "source": [
    "##### Jeśli zastosujemy rozkład jednostajny (wszystkie prawdopodobieństwa takie same) to funkcja kosztu wyniesie:\n",
    "$$ -log(\\frac{1}{n}) $$\n",
    "* to jest dobry punkt odniesienia, żeby sprawdzić na ile nasz model jest lepszy od losowego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec637f-ca78-439d-ad2a-20e5bcfe6b8b",
   "metadata": {
    "id": "61ec637f-ca78-439d-ad2a-20e5bcfe6b8b"
   },
   "outputs": [],
   "source": [
    "# punkt odniesienia dla jednakowych prawdopodobieństw\n",
    "- np.log(1/n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35645444-475a-4068-8934-7077ce55cd42",
   "metadata": {
    "id": "35645444-475a-4068-8934-7077ce55cd42"
   },
   "source": [
    "#### Pętla uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e5088-19ac-4244-a24c-591bb6ebe152",
   "metadata": {
    "id": "155e5088-19ac-4244-a24c-591bb6ebe152"
   },
   "outputs": [],
   "source": [
    "n_steps = 1500\n",
    "batch_size = 2048\n",
    "W = #TODO zainicjalizuj macierz wag liczbami losowymi z rozkładu normalnego o średniej 0 i odchyleniu standardowym 0.01\n",
    "alpha = 5\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb2941-f6b0-4b39-8f6c-556fc618d415",
   "metadata": {
    "id": "1eeb2941-f6b0-4b39-8f6c-556fc618d415"
   },
   "source": [
    "Dla każdego kroku:\n",
    "1. Wyzerować gradienty\n",
    "2. Wylosować batch\n",
    "3. Wyznaczyć logity jako $xW$\n",
    "4. Wyznaczyć probs jako softmax z logitów\n",
    "5. Wyznaczyć wartość funkcji straty (loss) (entropia krzyżowa)\n",
    "6. Wyznaczyć gradienty\n",
    "7. Zaktualizować wagi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa71967-91c2-4e04-833c-556342d455de",
   "metadata": {
    "id": "9fa71967-91c2-4e04-833c-556342d455de"
   },
   "outputs": [],
   "source": [
    "for i in range(n_steps):\n",
    "    W.grad = None # czyszczenie gradientów przed nowymi\n",
    "    x, y = get_batch(batch_size=batch_size)\n",
    "    # TODO\n",
    "    probs =  # TODO\n",
    "    loss =  # TODO\n",
    "    losses.append(loss.item())\n",
    "    if i % 100 == 0:\n",
    "        print(\"Iteracja \", i, \", loss: \", loss.item())\n",
    "     \n",
    "    # TODO\n",
    "\n",
    "    with torch.no_grad():\n",
    "        W -= # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a6dbe9-80b6-424c-8ac7-e263ccd26f2c",
   "metadata": {
    "id": "f1a6dbe9-80b6-424c-8ac7-e263ccd26f2c"
   },
   "outputs": [],
   "source": [
    "plt.plot(losses);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462406ae-4624-46bb-9de8-33f95e315445",
   "metadata": {
    "id": "462406ae-4624-46bb-9de8-33f95e315445"
   },
   "source": [
    "##### Generacja tekstu za pomocą wyznaczonej macierzy W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56b6d5-803a-4dfe-b33e-8aca623b0731",
   "metadata": {
    "id": "5f56b6d5-803a-4dfe-b33e-8aca623b0731"
   },
   "outputs": [],
   "source": [
    "# normalizujemy macierz\n",
    "W_norm_counts = softmax(W)\n",
    "print(W_norm_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc786811-6ea3-4cdb-bdc2-ded7ec76d7c0",
   "metadata": {
    "id": "bc786811-6ea3-4cdb-bdc2-ded7ec76d7c0"
   },
   "outputs": [],
   "source": [
    "# tekst z macierzy z uczenia gradientowego\n",
    "print(generate_text(\"T\", W_norm_counts, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394ff1b-faac-40ca-8b39-5f38eea5a19e",
   "metadata": {
    "id": "e394ff1b-faac-40ca-8b39-5f38eea5a19e"
   },
   "outputs": [],
   "source": [
    "# tekst z macierzy zliczeń\n",
    "print(generate_text(\"T\", norm_counts, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea70096-f40a-49ff-b496-00346073d49b",
   "metadata": {
    "id": "7ea70096-f40a-49ff-b496-00346073d49b"
   },
   "outputs": [],
   "source": [
    "# Tekst z losowej macierzy\n",
    "print(generate_text(\"T\", norm_rand_counts, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93e299-4ab8-4f35-9c9d-0226680707da",
   "metadata": {
    "id": "6a93e299-4ab8-4f35-9c9d-0226680707da"
   },
   "source": [
    "##### Porównanie wartości w macierzach\n",
    "* oglądamy pierwszy wiersz\n",
    "* po lewej macierz z uczenia\n",
    "* po prawej macierz zliczeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7802e-a2e3-4759-97f8-00fdbfe41955",
   "metadata": {
    "id": "1cd7802e-a2e3-4759-97f8-00fdbfe41955"
   },
   "outputs": [],
   "source": [
    "cols = 5\n",
    "\n",
    "for i in range(0, len(norm_counts), cols):\n",
    "    row1 = W_norm_counts[0][i:i+cols].tolist()\n",
    "    row2 = norm_counts[0][i:i+cols].tolist()\n",
    "\n",
    "    row1_str = \"  \".join(f\"{float(x):.4f}\" for x in row1)\n",
    "    row2_str = \"  \".join(f\"{float(x):.4f}\" for x in row2)\n",
    "\n",
    "    print(row1_str, \" | \", row2_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab9be8-5bfd-4052-8586-4439ecccc50e",
   "metadata": {
    "id": "fbab9be8-5bfd-4052-8586-4439ecccc50e"
   },
   "source": [
    "## Wnioski\n",
    "1. Proszę porównać tekst generowany na podstawie: losowej macierzy, macierzy zliczeń i macierzy z uczenia\n",
    "2. Jak można poprawić algorytm uczenia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04621d0-5b17-40d1-8e54-e338d239ed97",
   "metadata": {
    "id": "e04621d0-5b17-40d1-8e54-e338d239ed97"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dydaktyka_LLM",
   "language": "python",
   "name": "dydaktyka_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
